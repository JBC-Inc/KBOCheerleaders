% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/data_mining.R
\name{fetchHTML}
\alias{fetchHTML}
\title{Fetch and Parse Content from URLs}
\usage{
fetchHTML(urls, return_type = c("html", "string"))
}
\arguments{
\item{urls}{A character vector containing one or more URLs. If a single URL
is provided as a string, it will be converted to a vector internally.}

\item{return_type}{A character string specifying the return type. Options
are \code{"html"} (default) to return parsed HTML documents using
\code{httr2::resp_body_html()} or \code{"string"} to return raw HTML as strings
using \code{httr2::resp_body_string()}.}
}
\value{
If a single URL is provided, the function returns the requested
content (HTML document or raw HTML string). If multiple URLs are provided,
the function returns a list of the requested content (or \code{NULL} if a request
fails).
}
\description{
This function retrieves content from one or more URLs using the \code{httr2}
package. It supports returning either parsed HTML documents or raw HTML
strings. The function includes error handling for failed requests, non-200
HTTP status codes, and other issues.
}
\details{
The function performs HTTP GET requests and either parses the HTML
content or returns it as a string, depending on the \code{return_type} argument.
If an error occurs (e.g., network issues, invalid URLs), or if the HTTP
status is 400 or above, the function will handle the error gracefully and
return \code{NULL} for that URL.
}
\keyword{internal}
